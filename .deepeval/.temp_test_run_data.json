{"testCases": [{"name": "test_case_0", "input": "Qual foi a temperatura m\u00e9dia?", "actualOutput": "A temperatura m\u00e9dia foi de 22.719C.", "expectedOutput": "A temperatura m\u00e9dia correta \u00e9 21.691C", "retrievalContext": ["timestamp: 2025-12-09T23:58:35.315878. temperature: 17.15C. accelerometer ax=0.0309, ay=0.0521, az=0.9909. gyroscope gx=0.0535, gy=-0.019, gz=0.0165.", "timestamp: 2025-12-10T00:23:21.315878. temperature: 18.18C. accelerometer ax=-0.1623, ay=0.0693, az=0.6516. gyroscope gx=0.1249, gy=-0.3535, gz=0.3795.", "timestamp: 2025-12-09T21:53:04.315878. temperature: 22.51C. accelerometer ax=-0.0153, ay=0.007, az=1.0048. gyroscope gx=0.0199, gy=-0.0053, gz=-0.0094.", "timestamp: 2025-12-10T00:13:38.315878. temperature: 25.32C. accelerometer ax=0.0553, ay=-0.0969, az=1.3032. gyroscope gx=0.0173, gy=-0.3813, gz=-0.0597.", "timestamp: 2025-12-10T00:09:47.315878. temperature: 25.24C. accelerometer ax=0.0557, ay=0.038, az=0.9907. gyroscope gx=-0.075, gy=-0.0521, gz=0.0309.", "timestamp: 2025-12-09T21:53:35.315878. temperature: 19.26C. accelerometer ax=0.0193, ay=-0.0038, az=0.9963. gyroscope gx=-0.0135, gy=-0.0101, gz=0.0051.", "timestamp: 2025-12-10T00:13:13.315878. temperature: 30.08C. accelerometer ax=0.3533, ay=0.064, az=0.6448. gyroscope gx=-0.3835, gy=-0.2567, gz=-0.2019.", "timestamp: 2025-12-09T22:58:57.315878. temperature: 24.1C. accelerometer ax=-0.0008, ay=-0.0135, az=0.9944. gyroscope gx=-0.0137, gy=-0.003, gz=0.0021.", "timestamp: 2025-12-09T21:46:15.315878. temperature: 24.0C. accelerometer ax=-0.0102, ay=-0.0045, az=0.9903. gyroscope gx=-0.0199, gy=-0.0064, gz=-0.0035.", "timestamp: 2025-12-09T23:03:43.315878. temperature: 21.35C. accelerometer ax=-0.0135, ay=-0.009, az=0.9945. gyroscope gx=0.0051, gy=0.0121, gz=-0.0038."], "success": false, "metricsData": [{"name": "Contextual Precision", "threshold": 0.5, "success": false, "strictMode": false, "evaluationModel": "gpt-4.1", "evaluationCost": 0.0}, {"name": "Contextual Recall", "threshold": 0.5, "success": false, "strictMode": false, "evaluationModel": "gpt-4.1", "evaluationCost": 0.0}, {"name": "Contextual Relevancy", "threshold": 0.5, "success": false, "strictMode": false, "evaluationModel": "gpt-4.1", "evaluationCost": 0.0}], "runDuration": 1.6000789999998233, "evaluationCost": 0.0, "order": 0}], "conversationalTestCases": [], "metricsScores": [], "runDuration": 0.0, "evaluationCost": 0.0}